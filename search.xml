<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>categoriestest</title>
      <link href="/2020/02/02/categoriestest/"/>
      <url>/2020/02/02/categoriestest/</url>
      
        <content type="html"><![CDATA[<pre><code>print(&quot;这是一个分类测试文件&quot;)</code></pre>]]></content>
      
      
      <categories>
          
          <category> 分类 </category>
          
          <category> 测试 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分类 </tag>
            
            <tag> 测试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>激活函数</title>
      <link href="/2020/02/02/tagstest/"/>
      <url>/2020/02/02/tagstest/</url>
      
        <content type="html"><![CDATA[<h1 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h1><blockquote><p>   如果网络中每个神经元输入为所有输入的加权和，那最后的结果将是整个神经网络成为一个线性模型。将每个神经元（也就是神经网络中的节点）的输出通过一个非线性函数，那么整个<br>神经网络也就不再是线性的了，这个非线性的函数我们通常会称之为“激活函数(Activation Function)”。<br><img src="https://s2.ax1x.com/2020/02/04/1De2FJ.png" alt="神经元"></p></blockquote><h1 id="Why？（为什么要使用激活激活函数函数？）"><a href="#Why？（为什么要使用激活激活函数函数？）" class="headerlink" title="Why？（为什么要使用激活激活函数函数？）"></a>Why？（为什么要使用激活激活函数函数？）</h1><blockquote><p>   如果不用激励函数（其实相当于激励函数是f(x) = x），在这种情况下你每一层节点的输入都是上层输出的线性函数，很容易验证，无论你神经网络有多少层，输出都是输入的线性组合，与没有隐藏层效果相当，这种情况就是最原始的感知机（Perceptron）了，那么网络的逼近能力就相当有限。正因为上面的原因，我们决定引入非线性函数作为激励函数，这样深层神经网络表达能力就更加强大（不再是输入的线性组合，而是几乎可以逼近任意函数）。</p></blockquote><h2 id="常用的激活函数"><a href="#常用的激活函数" class="headerlink" title="常用的激活函数"></a>常用的激活函数</h2><blockquote><ol><li>ReLu激活函数，这是一个在输入和0之间求最大值的函数。<br>$$ f(z)=max\lbrace0,z\rbrace $$<br>加入ReLU激活函数的神经元被称为整流线性单元。整流线性单元和线性单元非常类似，两者的唯一区别在于整流线性单元在其一半的定义域上输出为0。</li><li>sigmoid激活函数。$$ f(z)= \frac{1}{1+e^{-{z}}} \quad$$</li></ol></blockquote>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度前馈神经网络</title>
      <link href="/2020/02/01/%E6%B7%B1%E5%BA%A6%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2020/02/01/%E6%B7%B1%E5%BA%A6%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><blockquote><p>定义：深度前馈神经网络，可简称为前馈神经网络，指的是具有前馈特征的一类神经网络模型。实际上深度神经网络应该泛指更多的使用了深度学习技术的深度神经网络模型。</p></blockquote><h2 id="网络的前馈方式"><a href="#网络的前馈方式" class="headerlink" title="网络的前馈方式"></a>网络的前馈方式</h2><blockquote><p>前馈神经网络模型是向前的，在模型的输出和模型本身之间并不存在连接，也就不构成反馈。例如，对于一个分类器功能的MLP，假设其输入，输出满足一个函y=f(x)(其中x是原始数据的载体，也就是网络的输入)，信息从输入的x经过定义的功能函数f,最终到达输出y。在这个过程中，f以及x并没有因为y的取值而受到任何影响。</p></blockquote><h2 id="全连接"><a href="#全连接" class="headerlink" title="全连接"></a>全连接</h2><blockquote><p>全连接与稀疏连接都指的是神经网络模型中相邻两层单元间的连接方式。<br>全部使用全连接方式的网络，通常成为全连神经网络；仅某一层由全连方式得到。则称之为全连层。MLP就是一个全连神经网络，卷积神经网络则是一个使用了稀疏连接的典型网络。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
          <category> 深度学习 </category>
          
          <category> 神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 神经网络 </tag>
            
            <tag> 人工智能 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2020/02/01/hello-world/"/>
      <url>/2020/02/01/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
