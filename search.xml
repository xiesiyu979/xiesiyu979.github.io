<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>损失函数</title>
      <link href="/2020/02/02/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"/>
      <url>/2020/02/02/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h1><blockquote><p>&nbsp;&nbsp;为了训练解决分类问题或回归问题的模型，我们通常会定义一个损失函数来描述对问题的求解精度（用数学的方式刻画预测答案和真实答案之间的距离）。Loss越小，代表模型得到的结果与真实值的偏差越小，也就是说模型越精确。</p></blockquote><h2 id="经典的损失函数"><a href="#经典的损失函数" class="headerlink" title="经典的损失函数"></a>经典的损失函数</h2><blockquote><ol><li>交叉熵损失函数<br>&nbsp;&nbsp;在解决深度学习领域的一些问题时，交叉熵用于刻画两个概率分布向量之间的距离，是<em>分类问题_中使用比较广的一种损失函数。<br>$$L=-{\sum</em>{x}^M}y_c\log(p_c)$$<br>其中:<br>&nbsp;&nbsp;- $$M$$：类别的数量.<br>&nbsp;&nbsp;- $${y_c}$$：指示变量（0或1），如果该类别和样本的类别相同就是1，否则是0.<br>&nbsp;&nbsp;- $${p_c}$$：对于观测样本属于类别 [公式] 的预测概率.<br>交叉熵计算(by知乎<a href="https://zhuanlan.zhihu.com/p/35709485" target="_blank" rel="noopener">飞鱼说人工智能</a>)  </li><li>均方误差损失函数<br>&nbsp;&nbsp;对于回归问题，最常用的损失函数就是均方误差损失函数。<br>$$MSE(y,y^{‘})=\frac{\sum_{i=1}^n(y_i-{y_i^{‘}})^2}{n}$$<br>其中$$y_i$$为第一个batch中第$$i$$个数据的答案值，而$$y_i^{‘}$$也就是神经网络给出的预测值。解决回归问题的网络模型就是以最小化该函数为目标。<br>均方误差计算(by知乎<a href="https://zhuanlan.zhihu.com/p/35709485" target="_blank" rel="noopener">飞鱼说人工智能</a>) <img src="https://s2.ax1x.com/2020/02/04/1rCxu4.png" alt="图一"><br><img src="https://s2.ax1x.com/2020/02/04/1rPSb9.png" alt="图二"></li></ol></blockquote>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>激活函数</title>
      <link href="/2020/02/02/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"/>
      <url>/2020/02/02/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h1><blockquote><p>   如果网络中每个神经元输入为所有输入的加权和，那最后的结果将是整个神经网络成为一个线性模型。将每个神经元（也就是神经网络中的节点）的输出通过一个非线性函数，那么整个<br>神经网络也就不再是线性的了，这个非线性的函数我们通常会称之为“激活函数(Activation Function)”。<br><img src="https://s2.ax1x.com/2020/02/04/1De2FJ.png" alt="神经元"></p></blockquote><h1 id="Why？（为什么要使用激活激活函数函数？）"><a href="#Why？（为什么要使用激活激活函数函数？）" class="headerlink" title="Why？（为什么要使用激活激活函数函数？）"></a>Why？（为什么要使用激活激活函数函数？）</h1><blockquote><p>   如果不用激励函数（其实相当于激励函数是f(x) = x），在这种情况下你每一层节点的输入都是上层输出的线性函数，很容易验证，无论你神经网络有多少层，输出都是输入的线性组合，与没有隐藏层效果相当，这种情况就是最原始的感知机（Perceptron）了，那么网络的逼近能力就相当有限。正因为上面的原因，我们决定引入非线性函数作为激励函数，这样深层神经网络表达能力就更加强大（不再是输入的线性组合，而是几乎可以逼近任意函数）。<br>  对与我们来说，通常不可能预先预测出哪种激活函数工作得最好，所以也很难以决定使用哪种激活函数最好。可以通过一些直觉来尝试一些激活函数，如果认为某种隐藏单元可能表现良好，就用它组成神经网络进行训练，最后进行一些评估。</p></blockquote><h2 id="常用的激活函数"><a href="#常用的激活函数" class="headerlink" title="常用的激活函数"></a>常用的激活函数</h2><blockquote><ol><li>ReLu激活函数，这是一个在输入和0之间求最大值的函数。<br>$$ f(z)=max\lbrace0,z\rbrace $$<br>加入ReLU激活函数的神经元被称为整流线性单元。整流线性单元和线性单元非常类似，两者的唯一区别在于整流线性单元在其一半的定义域上输出为0。</li><li>sigmoid激活函数，它能够把输入的连续实值变换为0和1之间的输出，特别的，如果是非常大的负数，那么输出就是0；如果是非常大的正数，输出就是1。<br>$$ f(z)= \frac{1}{1+e^{-{z}}} \quad$$<br>sigmoid函数曾经被使用的很多，不过近年来，用它的人越来越少了。主要是因为它固有的一些 缺点。(1)在深度神经网络中梯度反向传递时导致梯度爆炸和梯度消失，其中梯度爆炸发生的概率非常小，而梯度消失发生的概率比较大。(2)sigmoid 的 output 不是0均值（即zero-centered）。这是不可取的，因为这会导致后一层的神经元将得到上一层输出的非0均值的信号作为输入。(3)其解析式中含有幂运算，计算机求解时相对来讲比较耗时。对于规模比较大的深度网络，这会较大地增加训练时间。</li><li>tanh激活函数，在引入整流线性单元之前，双曲正切激活函数也经常会被用到，它被定义为：<br>$$ f(z)= \frac{1-e^{-{2z}}}{1+e^{-{2z}}} \quad$$</li></ol></blockquote>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度前馈神经网络</title>
      <link href="/2020/02/01/%E6%B7%B1%E5%BA%A6%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2020/02/01/%E6%B7%B1%E5%BA%A6%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><blockquote><p>定义：深度前馈神经网络，可简称为前馈神经网络，指的是具有前馈特征的一类神经网络模型。实际上深度神经网络应该泛指更多的使用了深度学习技术的深度神经网络模型。</p></blockquote><h2 id="网络的前馈方式"><a href="#网络的前馈方式" class="headerlink" title="网络的前馈方式"></a>网络的前馈方式</h2><blockquote><p>前馈神经网络模型是向前的，在模型的输出和模型本身之间并不存在连接，也就不构成反馈。例如，对于一个分类器功能的MLP，假设其输入，输出满足一个函y=f(x)(其中x是原始数据的载体，也就是网络的输入)，信息从输入的x经过定义的功能函数f,最终到达输出y。在这个过程中，f以及x并没有因为y的取值而受到任何影响。</p></blockquote><h2 id="全连接"><a href="#全连接" class="headerlink" title="全连接"></a>全连接</h2><blockquote><p>全连接与稀疏连接都指的是神经网络模型中相邻两层单元间的连接方式。<br>全部使用全连接方式的网络，通常成为全连神经网络；仅某一层由全连方式得到。则称之为全连层。MLP就是一个全连神经网络，卷积神经网络则是一个使用了稀疏连接的典型网络。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
          <category> 深度学习 </category>
          
          <category> 神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 神经网络 </tag>
            
            <tag> 人工智能 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2020/02/01/hello-world/"/>
      <url>/2020/02/01/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
